{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNC:\n",
    "    def __init__(self,input_size,output_size,seq_len,num_words,word_size,read_heads):\n",
    "        with tf.device('/device:GPU:1'):\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "\n",
    "            self.num_words = num_words\n",
    "            self.word_size = word_size\n",
    "\n",
    "            self.read_heads = read_heads\n",
    "\n",
    "            self.interface_size = (word_size*read_heads) + (3*word_size)+ (5*read_heads)+3\n",
    "\n",
    "            self.controller_input_size = (read_heads*word_size)+input_size\n",
    "\n",
    "            self.controller_output_size = output_size + self.interface_size\n",
    "\n",
    "            self.output_vector = tf.truncated_normal([1,self.output_size],stddev=0.1)\n",
    "            self.interface_vector = tf.truncated_normal([1,self.interface_size],stddev=0.1)\n",
    "\n",
    "            self.memory_matrix = tf.zeros([num_words,word_size])\n",
    "\n",
    "            self.usage_vector = tf.fill([num_words,1],1e-6)\n",
    "            self.temp_link_matrix = tf.zeros([num_words,num_words])\n",
    "\n",
    "            self.precedence_weighting  = tf.zeros([num_words,1])\n",
    "\n",
    "            self.read_weightings = tf.fill([num_words,read_heads],1e-6)\n",
    "            self.write_weightings = tf.fill([num_words,1],1e-6)\n",
    "            self.read_vectors = tf.fill([read_heads,word_size],1e-6)\n",
    "\n",
    "            # Controller\n",
    "            self.input_x = tf.placeholder(tf.float32,shape=[seq_len*2,self.input_size],name = \"input_x\")\n",
    "            self.output_y = tf.placeholder(tf.float32,shape=[seq_len*2,self.output_size],name=\"output_y\")\n",
    "\n",
    "\n",
    "            self.weights1 = tf.get_variable(\"weights1\",shape=[self.controller_input_size,32],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.biases1 = tf.get_variable(\"biases1\",shape=[32],initializer=tf.zeros_initializer())\n",
    "            self.weights2 = tf.get_variable(\"weights2\",shape=[32,self.controller_output_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.biases2 = tf.get_variable(\"biases2\",shape=[self.controller_output_size])\n",
    "\n",
    "            self.output_vector_weights = tf.get_variable(\"Wy\",shape=[self.controller_output_size,self.output_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.interface_weights = tf.get_variable(\"Wiv\",shape=[self.controller_output_size,self.interface_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "            self.read_vectors_weights = tf.get_variable(\"Wr\",shape=[self.read_heads*self.word_size,self.output_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "    def content_lookup(self,key,key_strength):\n",
    "        normalized_memory = tf.nn.l2_normalize(self.memory_matrix,1)\n",
    "        normalized_key = tf.nn.l2_normalize(key,0)\n",
    "        \n",
    "        z = tf.matmul(normalized_memory,normalized_key,transpose_b=True)\n",
    "        \n",
    "        return tf.nn.softmax(key_strength*z)\n",
    "    \n",
    "    # used to provided new locations for writing\n",
    "    def calc_allocation_weighting(self):\n",
    "        # multiply usage vector by -1 to get locations in ascending order of usage\n",
    "        sorted_usage_vector,free_list = tf.nn.top_k(-1*self.usage_vector,k = self.num_words)\n",
    "        # since usage vector was multiplied by -1,after sorted, return to its original value\n",
    "        sorted_usage_vector = sorted_usage_vector*-1\n",
    "        \n",
    "        cumulative_product = tf.cumprod(sorted_usage_vector,axis=0,exclusive=True)\n",
    "        unordered_allocation_weighting =  (1-sorted_usage_vector)*cumulative_product\n",
    "        \n",
    "        allocation_weights = tf.zeros([self.num_words])\n",
    "        identity_matrix = tf.constant(np.identity(self.num_words,dtype=np.float32))\n",
    "        \n",
    "        for pos, idx in enumerate(tf.unstack(free_list[0])):\n",
    "            #flatten\n",
    "            m = tf.squeeze(tf.slice(identity_matrix, [idx, 0], [1, -1]))\n",
    "            #add to weight matrix\n",
    "            allocation_weights += m*unordered_allocation_weighting[0, pos]\n",
    "        #the allocation weighting for each row in memory\n",
    "        return tf.reshape(allocation_weights, [self.num_words, 1])\n",
    "\n",
    "    \n",
    "    def one_plus(self,x):\n",
    "        return 1+tf.nn.softplus(x)\n",
    "    \n",
    "    def time_step(self,x):\n",
    "        step_input = tf.concat([x,tf.reshape(self.read_vectors,[1,self.read_heads*self.word_size])],1)\n",
    "        \n",
    "        #controller forward propagation\n",
    "        layer1_activation = tf.nn.relu(tf.matmul(step_input,self.weights1)+self.biases1)\n",
    "        #print(\"layer 1 act\",layer1_activation)\n",
    "        layer2_activation = tf.nn.relu(tf.matmul(layer1_activation,self.weights2)+self.biases2)\n",
    "        #print(\"layer 2 act\",layer2_activation)\n",
    "        \n",
    "        #output vector\n",
    "        self.output_vector = tf.matmul(layer2_activation,self.output_vector_weights)\n",
    "        #print(\"output vector\",self.output_vector)\n",
    "        \n",
    "        #interface vector\n",
    "        self.interface_vector = tf.matmul(layer2_activation,self.interface_weights)\n",
    "        #print(self.interface_vector)\n",
    "        \n",
    "        #Interact with the memory(read and write)\n",
    "        ##Slice interface vector to get the 10 components of it, the partition its an indexes vector(values from 0 to 9)\n",
    "        partition_indexes = tf.constant([[0]*(self.read_heads*self.word_size) #read keys\n",
    "                                +[1]*(self.read_heads)#read strengths \n",
    "                                +[2]*(self.word_size)\n",
    "                                +[3] #write strength\n",
    "                                +[4]*(self.word_size) #erase vector\n",
    "                                +[5]*(self.word_size) #write vector\n",
    "                                +[6]*(self.read_heads) #free gates\n",
    "                                +[7] #allocation gate\n",
    "                                +[8] #write gate\n",
    "                                +[9]*(self.read_heads*3) #read modes\n",
    "                                \n",
    "                                ],dtype = tf.int32)\n",
    "        \n",
    "        #print(partition_indexes)\n",
    "        (read_keys,read_strengths,write_key\n",
    "        ,write_strength,erase_vector,write_vector,\n",
    "        free_gates,allocation_gate,write_gate,read_modes) = tf.dynamic_partition(self.interface_vector,partition_indexes,10)\n",
    "        \n",
    "        ##Make every value have the correct shape and be in the correct domain\n",
    "        read_keys = tf.reshape(read_keys,[self.read_heads,self.word_size])\n",
    "        print(read_keys)\n",
    "        read_strengths = self.one_plus(read_strengths)\n",
    "        print(read_strengths)\n",
    "        \n",
    "        write_key = tf.expand_dims(write_key,0)\n",
    "        write_strength = self.one_plus(write_key)\n",
    "        \n",
    "        erase_vector = tf.nn.sigmoid(tf.expand_dims(erase_vector,0))\n",
    "        write_vector = tf.expand_dims(write_vector,0)\n",
    "        \n",
    "        free_gates =  tf.nn.sigmoid(tf.expand_dims(free_gates,0))\n",
    "        allocation_gate = tf.nn.sigmoid(allocation_gate)\n",
    "        write_gate = tf.nn.sigmoid(write_gate)\n",
    "        \n",
    "        read_modes = tf.nn.softmax(tf.reshape(read_modes,[3,self.read_heads]))\n",
    "        \n",
    "        \n",
    "        ## Writing to memory(dynamic allocation and content lookup)\n",
    "        ### dynamic memory allocation\n",
    "        retention_vector = tf.reduce_prod(1-free_gates*self.read_weightings,reduction_indices=1)\n",
    "        \n",
    "        self.usage_vector = (self.usage_vector + self.write_weightings  - self.usage_vector* self.write_weightings)*retention_vector\n",
    "        \n",
    "        allocation_weights = self.calc_allocation_weighting()\n",
    "        \n",
    "        ### content lookup for  writing\n",
    "        write_content_weigths = self.content_lookup(write_key,write_strength)\n",
    "        \n",
    "        ### final write weights\n",
    "        self.write_weightings = write_gate*(allocation_gate*allocation_weights+(1-allocation_gate)*write_content_weigths)\n",
    "        #print(self.write_weightings )\n",
    "        \n",
    "        ### final writing to memory(first erase, then write)\n",
    "        self.memory_matrix  = self.memory_matrix * (1-tf.matmul(self.write_weightings,erase_vector))+(tf.matmul(self.write_weightings,write_vector))\n",
    "        \n",
    "        ## reading from memory(by content and by temporal order)\n",
    "        \n",
    "        ### temporal order\n",
    "        #### temporal link matrix update using write weights, and previus precedence weighitngs\n",
    "        #print(\"antes weightis\",self.write_weightings)\n",
    "        write_weightsi = tf.matmul(self.write_weightings,tf.ones([1,self.num_words]))\n",
    "        #print(\"yua\")\n",
    "        #print(self.precedence_weighting)\n",
    "        self.temp_link_matrix = (1-write_weightsi-tf.transpose(write_weightsi)) * self.temp_link_matrix + tf.matmul(self.write_weightings,self.precedence_weighting,transpose_b=True)\n",
    "        self.temp_link_matrix = self.temp_link_matrix * (tf.ones([self.num_words,self.num_words]) - tf.constant(np.identity(self.num_words,dtype=np.float32)))\n",
    "        \n",
    "        ### read modes (backguard,content,forward)\n",
    "        back_weigthing = read_modes[0]*tf.matmul(self.temp_link_matrix,self.read_weightings,transpose_a=True)\n",
    "        #print(back_weigthing)\n",
    "        content_weigthing = read_modes[1]*self.content_lookup(read_keys,read_strengths)\n",
    "        #print(content_weigthing)\n",
    "        forward_weithing = read_modes[2]*tf.matmul(self.temp_link_matrix,self.read_weightings)\n",
    "        #print(forward_weithing)\n",
    "        \n",
    "        self.read_weightings  = back_weigthing + content_weigthing + forward_weithing\n",
    "        \n",
    "        self.read_vectors = tf.transpose(tf.matmul(self.memory_matrix,self.read_weightings,transpose_a=True))\n",
    "        #print(self.memory_matrix)\n",
    "        #print(self.read_weightings)\n",
    "        #print(self.read_vectors)\n",
    "        \n",
    "        ### apply weights to read vectors\n",
    "        weighted_read_vectors = tf.matmul(tf.reshape(self.read_vectors,[1,self.read_heads*self.word_size]),self.read_vectors_weights)\n",
    "        #print(self.output_vector)\n",
    "        #print(weighted_read_vectors)\n",
    "        return self.output_vector + weighted_read_vectors\n",
    "    \n",
    "    #output list of numbers (one hot encoded) by running the step function\n",
    "    def run(self):\n",
    "        big_out = []\n",
    "        for t, seq in enumerate(tf.unstack(self.input_x, axis=0)):\n",
    "            seq = tf.expand_dims(seq, 0)\n",
    "            y = self.time_step(seq)\n",
    "            big_out.append(y)\n",
    "        return tf.stack(big_out, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(argv=None):\n",
    "\n",
    "    #generate the input output sequences, randomly intialized\n",
    "    num_seq = 10\n",
    "    seq_len = 6\n",
    "    seq_width = 4\n",
    "    iterations = 1000\n",
    "    con = np.random.randint(0, seq_width,size=seq_len)\n",
    "    seq = np.zeros((seq_len, seq_width))\n",
    "    seq[np.arange(seq_len), con] = 1\n",
    "    end = np.asarray([[-1]*seq_width])\n",
    "    zer = np.zeros((seq_len, seq_width))\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        #training time\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            #init the DNC\n",
    "            dnc = DNC(input_size=seq_width, output_size=seq_width, seq_len=seq_len, num_words=10, word_size=4, read_heads=1)\n",
    "            \n",
    "            #calculate the predicted output\n",
    "            output = tf.squeeze(dnc.run())\n",
    "            #print(output,dnc.output_y)\n",
    "            #compare prediction to reality, get loss via sigmoid cross entropy\n",
    "            loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output, labels=dnc.output_y))\n",
    "            #print(loss)\n",
    "            #use regularizers for each layer of the controller\n",
    "            regularizers = (tf.nn.l2_loss(dnc.weights1) + tf.nn.l2_loss(dnc.weights2) +\n",
    "                            tf.nn.l2_loss(dnc.biases1) + tf.nn.l2_loss(dnc.biases2))\n",
    "            #to help the loss convergence faster\n",
    "            loss += 5e-4 * regularizers\n",
    "            #optimize the entire thing (memory + controller) using gradient descent. dope\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "            \n",
    "            #initialize input output pairs\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            final_i_data = np.concatenate((seq, zer), axis=0)\n",
    "            final_o_data = np.concatenate((zer, seq), axis=0)\n",
    "            #for each iteration\n",
    "            for i in range(0, iterations+1):\n",
    "                #feed in each input output pair\n",
    "                \n",
    "                feed_dict = {dnc.input_x : final_i_data, dnc.output_y: final_o_data}\n",
    "                #make predictions\n",
    "                print(final_i_data.shape,final_o_data.shape)\n",
    "                l, _, predictions = sess.run([loss, optimizer, output], feed_dict=feed_dict)\n",
    "                if i%100==0:\n",
    "                    print(i,l)\n",
    "            #print results\n",
    "            print(final_i_data)\n",
    "            print(final_o_data)\n",
    "            print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_1:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_2:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_6:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_23:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_11:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_44:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_16:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_65:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_21:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_86:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_26:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_107:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_31:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_128:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_36:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_149:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_41:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_170:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_46:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_191:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_51:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_212:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"Reshape_56:0\", shape=(1, 4), dtype=float32)\n",
      "Tensor(\"add_233:0\", shape=(?,), dtype=float32)\n",
      "(12, 4) (12, 4)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [10,4], In[1]: [1,4]\n\t [[Node: MatMul_6 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](mul_19, ExpandDims_3)]]\n\t [[Node: Squeeze_120/_741 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_22475_Squeeze_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'MatMul_6', defined at:\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-5be245e2ed29>\", line 2, in <module>\n    tf.app.run()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"<ipython-input-3-843b88c9ed7c>\", line 25, in main\n    output = tf.squeeze(dnc.run())\n  File \"<ipython-input-2-bde03500ba96>\", line 191, in run\n    y = self.time_step(seq)\n  File \"<ipython-input-2-bde03500ba96>\", line 152, in time_step\n    self.memory_matrix  = self.memory_matrix * (1-tf.matmul(self.write_weightings,erase_vector))+(tf.matmul(self.write_weightings,write_vector))\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2437, in _mat_mul\n    name=name)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [10,4], In[1]: [1,4]\n\t [[Node: MatMul_6 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](mul_19, ExpandDims_3)]]\n\t [[Node: Squeeze_120/_741 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_22475_Squeeze_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [10,4], In[1]: [1,4]\n\t [[Node: MatMul_6 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](mul_19, ExpandDims_3)]]\n\t [[Node: Squeeze_120/_741 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_22475_Squeeze_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5be245e2ed29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-843b88c9ed7c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m#make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_i_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_o_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [10,4], In[1]: [1,4]\n\t [[Node: MatMul_6 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](mul_19, ExpandDims_3)]]\n\t [[Node: Squeeze_120/_741 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_22475_Squeeze_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'MatMul_6', defined at:\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-5be245e2ed29>\", line 2, in <module>\n    tf.app.run()\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"<ipython-input-3-843b88c9ed7c>\", line 25, in main\n    output = tf.squeeze(dnc.run())\n  File \"<ipython-input-2-bde03500ba96>\", line 191, in run\n    y = self.time_step(seq)\n  File \"<ipython-input-2-bde03500ba96>\", line 152, in time_step\n    self.memory_matrix  = self.memory_matrix * (1-tf.matmul(self.write_weightings,erase_vector))+(tf.matmul(self.write_weightings,write_vector))\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2437, in _mat_mul\n    name=name)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/luis/anaconda2/envs/tf14_gpu_py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [10,4], In[1]: [1,4]\n\t [[Node: MatMul_6 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](mul_19, ExpandDims_3)]]\n\t [[Node: Squeeze_120/_741 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_22475_Squeeze_120\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
